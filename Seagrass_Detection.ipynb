{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d2439c-79ae-4bfc-8b06-a1f9cc54b992",
   "metadata": {},
   "source": [
    "# Section 1: Seagrass Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b8d9e-79a1-4c32-9f3c-c7933dcdf38b",
   "metadata": {},
   "source": [
    "This is Section 1 of the Seagrass Detection Code, which aims to find all seagrass within a given orthomosaic using color detection. It consists of 6 sections: Preparation, Cropping, Reflection Removal, Seagrass Detection, Selection Refining, and Seagrass Area Calculation.  \n",
    "Its outcome is a binary image in which all the seagrass is highlighted in white. This binary image can then be georeferenced in 'Section 2: Georeferencing' and used as raster, for example in QGIS. Further, this section calculates the area of the detected seagrass based on the pixel size, which is computed in Section 2.    \n",
    "In the beginning of every subsection, the input and final output is mentioned, and a brief explanation of the code is given. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a9ace-cddc-48df-a065-3dee8302a993",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 0: Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3897666-072b-40d2-b9b1-a213dc377e50",
   "metadata": {},
   "source": [
    "*Overview of the different libraries and their functions:*  \n",
    "cv2 - short for Computer Vision, image processing library  \n",
    "numpy - general data processing library  \n",
    "csv - short for Comma Seperated Values, used to save the coordinates resulting from the cropping step  \n",
    "os - used to access and save images to the specified directories    \n",
    "shapely - for geometric shapes, used to extract the area of interest  \n",
    "tqdm - used to display a progress bar for parts 2 of the code, which has a significant running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af13a1a5-99d2-46b7-88d9-9bb738876980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from shapely import Polygon\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df3b2585-9a6d-496f-9d0e-99a5f1fc5260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Image not loaded correctly. \n",
      "Check that there are no typos and that the image name does not include '.tif'.\n",
      "Currently, your path is: C:\\copy\\your\\source\\path\\here\\put_image_name_here.tif\n"
     ]
    }
   ],
   "source": [
    "# define the source path, results path, and image name\n",
    "# saving the image name as a variable allows for clear storage of the preliminary results\n",
    "source_path = r\"C:\\copy\\your\\source\\path\\here\"\n",
    "results_path = r\"C:\\copy\\your\\results\\path\\here\"\n",
    "image_name = \"put_image_name_here\"\n",
    "\n",
    "# save the image in a variable and check that it has loaded correctly \n",
    "image = cv2.imread(os.path.join(source_path, f\"{image_name}.tif\"))\n",
    "if image is None:\n",
    "    print(\"Error: Image not loaded correctly. \\nCheck that there are no typos and that the image name does not include '.tif'.\"\n",
    "         f\"\\nCurrently, your path is: {os.path.join(source_path, f\"{image_name}.tif\")}\")\n",
    "else:\n",
    "    print(\"The image was loaded correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c123220a-0402-4237-8279-0c214815e786",
   "metadata": {},
   "source": [
    "Throughout the code, two images are shown within the same window several times.  \n",
    "If you want the images to show up on top of each other: axis = 0, and if you want them to be next to each other: axis = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7965da79-99bc-4b11-b88b-abd8f7fd1a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c9109d-711b-4348-b3ea-a28febca30cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 1: Cropping the tif to the area of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f014e35-2d56-4a01-859d-688058a7b1f2",
   "metadata": {},
   "source": [
    "*Input: original tif (image)  \n",
    "Output: cropped image (cropped_image)*  \n",
    "This part of the code allows you to select an area of interest (the sea), based on which a mask is created. The mask is then overlayed with the original image and only the area within the mask is used for futher processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58aea6b8-be34-4a6e-a553-f80a348f604b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a series of points by clicking on the image.\n",
      "Press 'Enter' to finish the selection.\n",
      "Coordinates: (393, 38)\n",
      "Coordinates: (1302, 843)\n",
      "Coordinates: (2590, 1691)\n",
      "Coordinates: (3750, 2346)\n",
      "Coordinates: (5099, 2731)\n",
      "Coordinates: (6174, 2847)\n",
      "Coordinates: (6201, 1040)\n",
      "Coordinates: (6128, 970)\n",
      "Coordinates: (3788, 215)\n",
      "Coordinates: (1676, 0)\n",
      "Coordinates: (439, 42)\n"
     ]
    }
   ],
   "source": [
    "# select points around the area of interest based on which the mask will be created (crops out the land area and keeps the sea)\n",
    "def main():\n",
    " \n",
    "    # open a csv file to save the coordinates\n",
    "    with open(\"coordinates_shoreline.csv\", \"w\") as f:\n",
    "            \n",
    "        # display instructions in the console\n",
    "        print(\"Select a series of points by clicking on the image.\")\n",
    "        print(\"Press 'Enter' to finish the selection.\")\n",
    "        \n",
    "        # create a window for displaying the image\n",
    "        cv2.namedWindow(\"Point Selection\")\n",
    "        cv2.imshow(\"Point Selection\", image)\n",
    "        \n",
    "        # list to store the coordinate points\n",
    "        green_points = []\n",
    "        \n",
    "        # wait for the user to select points by clicking\n",
    "        def on_mouse_click(event, x, y, flags, param):\n",
    "            if event == cv2.EVENT_LBUTTONDOWN:\n",
    "     \n",
    "                # add the point to the list of green points\n",
    "                green_points.append((x, y))\n",
    "                \n",
    "                # display the clicked point in green\n",
    "                cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "                \n",
    "                # print the coordinates\n",
    "                print(\"Coordinates:\", (x, y))\n",
    "        \n",
    "                # save the coordinates in the csv file\n",
    "                with open(\"coordinates_shoreline.csv\", mode=\"w\", newline=\"\") as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerows(green_points)\n",
    "                \n",
    "                # draw a red line between the last two green points\n",
    "                if len(green_points) >= 2:\n",
    "                    pt1 = green_points[-2]\n",
    "                    pt2 = green_points[-1]\n",
    "                    cv2.line(image, (pt1[0], pt1[1]), (pt2[0], pt2[1]), (0, 0, 255), 2)\n",
    "                \n",
    "                # Update the image display\n",
    "                cv2.imshow(\"Point Selection\", image)\n",
    "\n",
    "        cv2.setMouseCallback(\"Point Selection\", on_mouse_click)\n",
    "        \n",
    "        # Wait for the user to press the 'Enter' key to finish the selection\n",
    "        while True:\n",
    "            key = cv2.waitKey(0)\n",
    "            if key == 13:  # 'Enter' key\n",
    "                break\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52fa4e68-c35a-4c62-816e-745dfb2ce292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mask based on the selected coordinates and crop the image\n",
    "\n",
    "# open the coordinates as a list and transform into a numpy array \n",
    "with open(\"coordinates_shoreline.csv\", \"r\") as file:\n",
    "    coord = list(csv.reader(file, quoting=csv.QUOTE_NONNUMERIC))\n",
    "pts = np.reshape((np.array(coord, np.int32)), (-1, 1, 2))\n",
    "\n",
    "# create a canvas (a black background) in the same shape as the original image, the mask will be saved on this canvas  \n",
    "canvas = np.zeros((np.shape(image)), dtype = 'uint8')\n",
    "\n",
    "# create a mask based on the previously selected points, polylines connects the points and fillConvexPoly then creates a polygon\n",
    "# (255, 255, 255) means the mask will be displayed in white\n",
    "mask = cv2.polylines(canvas, pts, True, (255,255,255))\n",
    "cv2.fillConvexPoly(mask, pts, (255, 255, 255))\n",
    "\n",
    "# overlay the mask and the original image using bitwise_and, only the area within the mask will be used in the following parts\n",
    "cropped_image = cv2.bitwise_and(mask, image)\n",
    "\n",
    "# show the mask next to the cropped area \n",
    "# if they show up next to each other when you want them stacked or vice versa, refer back to 'Part 0: Preparation' and change the axis value\n",
    "mask_and_cropped = np.concatenate((mask, cropped_image), axis = axis)\n",
    "cv2.imshow('Mask and Cropped Image', mask_and_cropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c1316-24fb-40e1-9d90-38552b9bdcc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 2: Removing the Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba5c3e-9e84-4525-811f-7820fb6724be",
   "metadata": {},
   "source": [
    "*input: cropped image (cropped_image)  \n",
    "output: image without reflection (image_without_reflection)*  \n",
    "This section of the code detects the reflection in the area of interest and then removes it. First, the image is converted from BGR to HSV (blue green red to hue saturation value), of which we are interested in the saturation specifically, as it is very high in when there is reflection. A modifiable threshold is given: all the pixels with a value within that threshold (meaning all pixels lighter than the minimum value) are then marked as reflections. The area around the relfections is then used to get the mean BGR colors, which are in turn applied to the reflection. A tif file in which the selected pixels are highlighted is created to allow for user interaction and easier adatpation of the code, and a tif file without the reflection is the final result of this section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e8d0e0b-e09f-4305-b129-7e9da309dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the BGR image to HSV and split to access the saturation only\n",
    "imghsv = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2HSV)\n",
    "(h, s, v) = cv2.split(imghsv)\n",
    "\n",
    "# create a binary image based on the saturation: the first value can be modified, the second (255) should remain the same\n",
    "# Increasing the first number will increase the number of reflections detected, decreasing it will decrease the number of reflections detected\n",
    "_, binary = cv2.threshold(s, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "cropped_binary = cv2.bitwise_and(binary, mask[:,:,0])\n",
    "reflection_vs_original = np.concatenate((cropped_image[:,:,0], cropped_binary), axis=axis)\n",
    "cv2.imshow('Detected Reflection', reflection_vs_original)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00f3810f-b9df-4dd8-a043-b238614b5d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function that replaces white pixels with average colour around them\n",
    "            \n",
    "def replace_white_color(image, contours): \n",
    "    i = 0\n",
    "    for contour in contours: \n",
    "        #Create a blank mask for each contour\n",
    "        white_mask = np.zeros(cropped_image.shape[:2], dtype=np.uint8)\n",
    "        \n",
    "        # Draw contour onto the mask\n",
    "        cv2.drawContours(white_mask, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "        # Dilate the mask to include a border around the contour\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        dilated_white_mask = cv2.dilate(white_mask, kernel, iterations=1)\n",
    "\n",
    "        # Calculate the area covered by the dilated mask excluding the original mask\n",
    "        mask_diff = cv2.subtract(dilated_white_mask, white_mask)\n",
    "\n",
    "        # Apply the mask difference to the original image and calculate the mean color\n",
    "        mean_color = cv2.mean(image, mask=mask_diff)[:3]            \n",
    "        mean_color = tuple([int(c) for c in mean_color])\n",
    "    \n",
    "        # Replace the color in the modified image only where white_mask is 255\n",
    "        image[dilated_white_mask == 255] = mean_color\n",
    "        i += 1\n",
    "        pbar.update(1)\n",
    "    print(\"Number of detected and processed contours:\", len(contours))\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35a413d4-1885-41bf-9540-918f2e968db7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013 contours were detected. Based on previous experience removing the reflection will take approximately 13.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Find all the contours (white zones) in the binary image\n",
    "contours, _ = cv2.findContours(cropped_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw the contours on the original image and run the reflection removal code\n",
    "image_with_contours = cropped_image.copy()\n",
    "cv2.drawContours(image_with_contours, contours, -1, (0, 255, 255), -1)\n",
    "print(len(contours), 'contours were detected. Based on previous experience removing the reflection will take approximately', round(len(contours)/1000*6.7, 0), 'minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88336a0c-ccc4-4cf2-ba6f-28ae5b529713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed Contours: 100%|\u001b[36m██████████████████████████████████████████████████████████\u001b[0m| 2013/2013 [02:48<00:00, 11.97it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected and processed contours: 2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove the reflection by replacing white contours with the average color of the area around them\n",
    "# displays a progress bar\n",
    "# if you run this code multiple times, there might be an issue with the progress bar (for every perecentage a new line appears) \n",
    "# if this happens, run: pbar.close() before the rest of the code\n",
    "#pbar.close()\n",
    "pbar = tqdm(total = len(contours), desc = 'Processed Contours', colour = 'cyan')\n",
    "image_filled = replace_white_color(cropped_image.copy(), contours)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6df27185-8eec-4382-9e65-146d524f4d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image with the contours of white pixels highlighted in yellow\n",
    "concatenated_image = np.concatenate((image_with_contours, image_filled), axis=axis) \n",
    "\n",
    "cv2.imshow(\"Detected Reflection (yellow) and Image without Reflection\", concatenated_image)\n",
    "cv2.imwrite(os.path.join(results_path, f\"{image_name}_withoutReflection.tif\"), image_filled)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cdd178-5a7d-4e20-a82d-17d96b0968e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 3: Identifying the Seagrass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028f14ae-0b51-4f51-ac6e-ca684c81fd32",
   "metadata": {},
   "source": [
    "*input: cropped image without reflection (image_without_reflection)  \n",
    "output: binary image where seagrass appears in white (dbo_binary)*  \n",
    "Part 3 of the code aims to select all the seagrass within the cropped image without reflection based on color detection. First, the image is converted from RGB (red green blue) to HSV (hue saturation value), for which the threshold values can then be set. A window opens up in which all the detected areas are outlined. As the values differ significantly from image to image, another window opens up in the next step, from which you can select points for which you would like to know the HSV values. You can then modify the thresholds and repeat this several times until you are happy with the selection.  \n",
    "At the end of this subsection, the outlines will most likely still contain some noise and some holes within your patches, which will be fixed in 'Part 4: Refining Selection'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07b6e01f-d095-4449-8026-405eb6266ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image without reflection\n",
    "image_without_reflection = cv2.imread(os.path.join(results_path, f\"{image_name}_withoutReflection.tif\"), image_filled)\n",
    "if image_without_reflection is None:\n",
    "    print(\"The image did not load correctly.\")\n",
    "\n",
    "# define the function that will select all dark blue objects within the given thresholds\n",
    "def segment_dark_blue_objects(image, lower_bound, upper_bound):\n",
    "    hsv_image = cv2.cvtColor(image_without_reflection, cv2.COLOR_BGR2HSV)\n",
    "    dark_blue_mask = cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
    "    dark_blue_objects = cv2.bitwise_and(image, image, mask=dark_blue_mask)\n",
    "    return dark_blue_objects\n",
    "\n",
    "# define the function that will draw outlines around the detected dark blue objects\n",
    "def draw_outlines(binary_image):\n",
    "    # find contours of binary image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # draw contours\n",
    "    image_with_contours = image_without_reflection.copy()\n",
    "    cv2.drawContours(image_with_contours, contours, -1, (0, 255, 255), 2)\n",
    "\n",
    "    # display outlines and save the image to your device\n",
    "    cv2.imshow('Outlines', image_with_contours)\n",
    "    cv2.imwrite(os.path.join(results_path, f'{image_name}_outlines.tif'), image_with_contours)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b3607b6-dc0a-4388-8e07-9956566ddabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment dark blue objects\n",
    "blue_min = np.array([97, 0, 65])\n",
    "blue_max = np.array([110, 255, 200])\n",
    "dark_blue_objects = segment_dark_blue_objects(image_without_reflection, blue_min, blue_max)\n",
    "\n",
    "# create binary of the dark blue objects (dbo) for further processing\n",
    "dbo_grayscale = cv2.cvtColor(dark_blue_objects, cv2.COLOR_RGB2GRAY)\n",
    "_, dbo_binary = cv2.threshold(dbo_grayscale, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# draw outlines around the selected objects\n",
    "draw_outlines(dbo_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3317c2c3-bd99-4c8e-93dc-094ac05bbde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102 236  67]\n",
      "[106 228  67]\n",
      "[104 223  72]\n",
      "[103 212  71]\n",
      "[104 223  72]\n",
      "[105 221  67]\n",
      "[106 214  69]\n",
      "[107 212  66]\n",
      "[105 226  70]\n",
      "[104 192  69]\n",
      "[106 161  87]\n"
     ]
    }
   ],
   "source": [
    "# open the outlined image\n",
    "image_with_contours = cv2.imread(os.path.join(results_path, f'{image_name}_outlines.tif'))\n",
    "if image_with_contours is None:\n",
    "    print(\"The image did not load correctly.\")\n",
    "\n",
    "# create an empty list to store the selected points\n",
    "seagrass_points = []\n",
    "\n",
    "# define the function which fills the list with the coordinates of points you've selected\n",
    "def on_mouse_click(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Add the point to the seagrass list\n",
    "        seagrass_points.append((y, x))\n",
    "                \n",
    "        # Display the clicked point in red\n",
    "        cv2.circle(image, (y, x), 2, (0, 0, 255), -1)\n",
    "\n",
    "# create a window in which the outlines image will be displayed, from which you can select the points for which you want the HSV values\n",
    "cv2.namedWindow(\"Seagrass Point Selection\")\n",
    "cv2.imshow(\"Seagrass Point Selection\", image_with_contours)\n",
    "cv2.setMouseCallback(\"Seagrass Point Selection\", on_mouse_click)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# print the HSV values of the selected points\n",
    "HSV = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2HSV)\n",
    "for point in seagrass_points:\n",
    "    print(HSV[point])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34c97b7-5cd2-45e9-af16-b9cb610416c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 4: Refining the Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "274fdecc-6fe7-4c67-a1ef-6f8566a399e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function which removes noise\n",
    "def remove_noise(image, kernel_size, iterations):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(kernel_size, kernel_size))\n",
    "    image_without_noise = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel, iterations = iterations)\n",
    "    return image_without_noise\n",
    "    \n",
    "# define the function which fill holes in the seagrass patches\n",
    "def fill_holes(image, kernel_size, iterations):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(kernel_size, kernel_size))\n",
    "    image_with_filled_patches = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel, iterations=iterations)\n",
    "    return image_with_filled_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "53df5b0d-8399-40d2-a425-17e144554443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove noise and fill up the holes in the seagrass patches\n",
    "# the kernel size and amount of iterations can be changed\n",
    "\n",
    "image_without_noise = remove_noise(dbo_binary, 3, 8)\n",
    "image_with_filled_patches = fill_holes(image_without_noise, 3, 10)\n",
    "\n",
    "draw_outlines(image_with_filled_patches)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "51b8dc46-6639-4aa3-a473-5f3b983d1f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when happy with the result, save the refined (binary) image to the results folder\n",
    "cv2.imwrite(os.path.join(results_path, f\"{image_name}_SeagrassBinary.tif\"), image_with_filled_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecfa93b-f3f6-4273-b2af-e0c8e1192892",
   "metadata": {},
   "source": [
    "Congratulations, this part of the code is now done! To continue working with the seagrass areas, please refer to the protocol and move on to Section 2, in which the binary tif is georeferenced to contain the same geographical information as the input orthomosaic. It can then be used as a raster, for example in QGIS. Return here once you're done with section 2 to calculate the area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab03db7-98dd-47e2-9e89-85b2ebdb706d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 6: Quantifying the Seagrass Areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2fe8cc-4098-417d-93df-b23c2111f6b7",
   "metadata": {},
   "source": [
    "*Input: Binary picture of the detected seagrass, pixel size  \n",
    "Output: Calculated Seagrass Area*  \n",
    "This section of the code calculates the detected seagrass area based on the pixel size, which is given through Section 2: Georeferencing. At a flying height of 100 metres, every pixel is approxiamtely equivalent to 5x5 cm. Based on the amount of detected pixels, the area is then calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9041ac9d-3d70-429d-9bc8-ccbcf7751bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function that computes the total amount of white pixels and then calculates the area in m2 and ha based on that\n",
    "\n",
    "def calculate_white_area(image, pixel_size):\n",
    " \n",
    "    # Check if the image was loaded correctly\n",
    "    if image is None:\n",
    "        print(\"Error: Image not loaded correctly.\")\n",
    "        return\n",
    "\n",
    "    # Count the number of white pixels (value 255)\n",
    "    white_pixel_count = cv2.countNonZero(image[:,:,0])\n",
    "\n",
    "    # Calculate the pixel area based on the pixel size\n",
    "    area_per_pixel_in_cm2 = pixel_size\n",
    "    area_per_pixel_in_m2 = area_per_pixel_in_cm2 / 10000\n",
    "\n",
    "    # Total area in square metres\n",
    "    area_m2 = white_pixel_count * area_per_pixel_in_m2\n",
    "\n",
    "    # Convert area to hectares\n",
    "    area_hectares = area_m2 / 10000\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Number of white pixels: {white_pixel_count}\")\n",
    "    print(f\"Area covered by one pixel: {round(area_per_pixel_in_cm2, 2)} square centimetres\")\n",
    "    print(f\"Covered area: {round(area_m2, 2)} square meters\")\n",
    "    print(f\"Covered area: {round(area_hectares, 4)} hectares\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e7c3f9e-afc8-4414-8598-428d4c13681e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of white pixels: 3577661\n",
      "Area covered by one pixel: 25.25 square centimetres\n",
      "Covered area: 9035.25 square meters\n",
      "Covered area: 0.9035 hectares\n"
     ]
    }
   ],
   "source": [
    "# Define inputs and run function\n",
    "seagrass_image = cv2.imread(os.path.join(results_path, f\"{image_name}_SeagrassBinary.tif\"))\n",
    "\n",
    "# pixel size in centimetres, copy from Part 5: Georeferencing\n",
    "pixel_size = 25.254630790658826\n",
    "\n",
    "# Calculate and display the white area\n",
    "calculate_white_area(seagrass_image, pixel_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SeagrassImagery",
   "language": "python",
   "name": "seagrassimagery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
