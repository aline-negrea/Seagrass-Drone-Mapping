{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d2439c-79ae-4bfc-8b06-a1f9cc54b992",
   "metadata": {},
   "source": [
    "# Seagrass Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b8d9e-79a1-4c32-9f3c-c7933dcdf38b",
   "metadata": {},
   "source": [
    "The following Code consists of 6 sections: Preparation, Cropping, Reflection Removal, Seagrass Detection, Selection Refining, and Seagrass Area Calculation.  \n",
    "The goal is to identify all the seagrass in a given tif file to then calculate its area in pixels, square metres, and hectars.  \n",
    "Further, it exports the detected seagrass areas as a shapefile which can be used in QGIS.   \n",
    "In the beginning of every section, the input and final output of the section is mentioned, and a brief explanation of the code is given. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a9ace-cddc-48df-a065-3dee8302a993",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3897666-072b-40d2-b9b1-a213dc377e50",
   "metadata": {},
   "source": [
    "Overview of the different libraries and their functions:  \n",
    "CV2: Short for Computer Vision, Image processing library  \n",
    "Numpy and Pandas: General data processing libraries  \n",
    "Ctypes: used to access another programming langauge called C++, used for accessing files within a computer (xxx)  \n",
    "CSV: Short for Comma Seperated Values, used to save the coordinates in a useful format  \n",
    "Shapely: for geometric shapes, used to extract the area of interest  \n",
    "tqdm: used to display progress bars for parts of the code that have significant running times  \n",
    "os: useful for saving iamges in specified folders by joining paths to specific images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af13a1a5-99d2-46b7-88d9-9bb738876980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from shapely import Polygon\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df3b2585-9a6d-496f-9d0e-99a5f1fc5260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the source path, results path, and image name\n",
    "# saving the image name as a variable allows for renaming and clear storage in the final section of the code\n",
    "# saves the image in a variable \n",
    "source_path = r\"C:\\Users\\aline\\Seagrass Mapping Drone\\Tifffiles\"\n",
    "image_name = \"AK_tryout\"\n",
    "image = cv2.imread(os.path.join(source_path, f\"{image_name}.tif\"))\n",
    "results_path = r\"C:\\Users\\aline\\Seagrass Mapping Drone\\Processed tiffs\"\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: Image not loaded correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c9109d-711b-4348-b3ea-a28febca30cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 1: Cropping the tif to the area of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f014e35-2d56-4a01-859d-688058a7b1f2",
   "metadata": {},
   "source": [
    "*Input: original tif (image)  \n",
    "Output: cropped image (cropped_image)*  \n",
    "This section of the code allows the user to select coordinates around the area of interest (the sea) and then uses a mask  to crop out everything ouside of that area. The mask is created by using the selected coordiantes as the corner points of a polygon. The mask and the original picture are then overlayed, and only the area within the polygon remains in the output image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58aea6b8-be34-4a6e-a553-f80a348f604b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a series of points by clicking on the image.\n",
      "Press 'Enter' to finish the selection.\n",
      "Coordinates: (3158, 7601)\n",
      "Coordinates: (3146, 7152)\n",
      "Coordinates: (2547, 7105)\n",
      "Coordinates: (2709, 7075)\n",
      "Coordinates: (2658, 6463)\n",
      "Coordinates: (2183, 6104)\n",
      "Coordinates: (1781, 5891)\n",
      "Coordinates: (1859, 5403)\n",
      "Coordinates: (2850, 4138)\n",
      "Coordinates: (2970, 3922)\n",
      "Coordinates: (2854, 3595)\n",
      "Coordinates: (2839, 3254)\n",
      "Coordinates: (3011, 2584)\n",
      "Coordinates: (3133, 2474)\n",
      "Coordinates: (3082, 2301)\n",
      "Coordinates: (3178, 1907)\n",
      "Coordinates: (3371, 1890)\n",
      "Coordinates: (3413, 1618)\n",
      "Coordinates: (3823, 1385)\n",
      "Coordinates: (4492, 1150)\n",
      "Coordinates: (5073, 1039)\n",
      "Coordinates: (5240, 782)\n",
      "Coordinates: (5494, 476)\n",
      "Coordinates: (5605, 244)\n",
      "Coordinates: (6023, 116)\n",
      "Coordinates: (6148, 76)\n",
      "Coordinates: (6546, 66)\n",
      "Coordinates: (7209, 290)\n",
      "Coordinates: (7327, 341)\n",
      "Coordinates: (7339, 534)\n",
      "Coordinates: (8021, 617)\n",
      "Coordinates: (8502, 782)\n",
      "Coordinates: (9556, 1175)\n",
      "Coordinates: (9774, 1278)\n",
      "Coordinates: (9260, 1888)\n",
      "Coordinates: (8669, 2190)\n",
      "Coordinates: (8277, 2704)\n",
      "Coordinates: (7467, 3989)\n",
      "Coordinates: (7169, 4500)\n",
      "Coordinates: (6736, 6566)\n",
      "Coordinates: (6727, 7291)\n",
      "Coordinates: (5593, 7575)\n",
      "Coordinates: (3167, 7583)\n",
      "Coordinates: (3134, 7566)\n"
     ]
    }
   ],
   "source": [
    "#get the coordinates of the area of interest (crops out the land area and keeps the sea)\n",
    "def main():\n",
    " \n",
    "    # Open a text file to save the coordinates\n",
    "    with open(\"coordinates_shoreline.csv\", \"w\") as f:\n",
    "            \n",
    "        # Display instructions in the console\n",
    "        print(\"Select a series of points by clicking on the image.\")\n",
    "        print(\"Press 'Enter' to finish the selection.\")\n",
    "        \n",
    "        # Create a window for displaying the image\n",
    "        cv2.namedWindow(\"Point Selection\")\n",
    "        cv2.imshow(\"Point Selection\", image)\n",
    "        \n",
    "        # List to store the red points\n",
    "        red_points = []\n",
    "        \n",
    "        # Wait for the user to select points by clicking\n",
    "        def on_mouse_click(event, x, y, flags, param):\n",
    "            if event == cv2.EVENT_LBUTTONDOWN:\n",
    "     \n",
    "                # Add the point to the list of red points\n",
    "                red_points.append((x, y))\n",
    "                \n",
    "                # Display the clicked point in red\n",
    "                cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "                \n",
    "                # Print the coordinates\n",
    "                print(\"Coordinates:\", (x, y))\n",
    "        \n",
    "                # Save the coordinates in the csv file\n",
    "                with open(\"coordinates_shoreline.csv\", mode=\"w\", newline=\"\") as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerows(red_points)\n",
    "                \n",
    "                # Draw a green line between the last two red points\n",
    "                if len(red_points) >= 2:\n",
    "                    pt1 = red_points[-2]\n",
    "                    pt2 = red_points[-1]\n",
    "                    cv2.line(image, (pt1[0], pt1[1]), (pt2[0], pt2[1]), (0, 0, 255), 2)\n",
    "                \n",
    "                # Update the image display\n",
    "                cv2.imshow(\"Point Selection\", image)\n",
    "\n",
    "        cv2.setMouseCallback(\"Point Selection\", on_mouse_click)\n",
    "        \n",
    "        # Wait for the user to press the 'Enter' key to finish the selection\n",
    "        while True:\n",
    "            key = cv2.waitKey(0)\n",
    "            if key == 13:  # 'Enter' key\n",
    "                break\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52fa4e68-c35a-4c62-816e-745dfb2ce292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a mask based on the selected coordinates\n",
    "\n",
    "# saving the coordinates in a list format\n",
    "with open(\"coordinates_shoreline.csv\", \"r\") as file:\n",
    "    coord = list(csv.reader(file, quoting=csv.QUOTE_NONNUMERIC))\n",
    "\n",
    "# read the image into cv2 and create an array of zeros in the same shape as the original image  \n",
    "canvas = np.zeros((np.shape(image)), dtype = 'uint8')\n",
    "\n",
    "# convert the coordinates to an array of the type int32\n",
    "coord_array = np.array(coord, np.int32)\n",
    "\n",
    "# feed the coordinate array into a new variable called pts (points) which is in a specific shape\n",
    "# draw polylines in shape of the sea area on the canvas, call it mask (the number 255 3x means it will be white)\n",
    "# this command only draws the lines but has no fill, use fillConvexPoly to fill the polygon\n",
    "pts = np.reshape(coord_array, (-1, 1, 2))\n",
    "mask = cv2.polylines(canvas, pts, True, (255,255,255))\n",
    "cv2.fillConvexPoly(mask, pts, (255, 255, 255))\n",
    "\n",
    "# display the created mask in a window (optional)\n",
    "cv2.namedWindow(\"Mask\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('Mask', mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b57d4e0b-eca9-4e42-8f23-266280ea2ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the mask as a new image and displaying it \n",
    "# bitwise_and overlaps the two images and keeps only the bits (pixels) where both of them overlap\n",
    "\n",
    "cropped_image = cv2.bitwise_and(mask, image)\n",
    "cv2.imshow('Cropped Image', cropped_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c1316-24fb-40e1-9d90-38552b9bdcc5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Part 2: Removing the Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba5c3e-9e84-4525-811f-7820fb6724be",
   "metadata": {},
   "source": [
    "*input: cropped image (cropped_image)  \n",
    "output: image without reflection (image_without_reflection)*  \n",
    "This section of the code detects the reflection in the area of interest and then removes it. First, the image is converted from BGR to HSV (blue green red to hue saturation value), of which we are interested in the saturation specifically, as it is very high in when there is reflection. A modifiable threshold is given: all the pixels with a value within that threshold (meaning all pixels lighter than the minimum value) are then marked as reflections. The area around the relfections is then used to get the mean BGR colors, which are in turn applied to the reflection. A tif file in which the selected pixels are highlighted is created to allow for user interaction and easier adatpation of the code, and a tif file without the reflection is the final result of this section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e8d0e0b-e09f-4305-b129-7e9da309dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the BGR image to HSV and split to access the saturation only\n",
    "imghsv = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2HSV)\n",
    "(h, s, v) = cv2.split(imghsv)\n",
    "\n",
    "# create a binary image based on the saturation: the first value can be modified, the second (255) should remain the same\n",
    "# Increasing the first number will increase the number of reflections detected, decreasing it will decrease the number of reflections detected\n",
    "_, binary = cv2.threshold(s, 25, 255, cv2.THRESH_BINARY_INV)\n",
    "cropped_binary = cv2.bitwise_and(binary, mask[:,:,0])\n",
    "reflection_vs_original = np.concatenate((cropped_image[:,:,0], cropped_binary), axis=0)\n",
    "cv2.imshow('Detected Reflection', reflection_vs_original)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00f3810f-b9df-4dd8-a043-b238614b5d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function that replaces white pixels with average colour around them\n",
    "            \n",
    "def replace_white_color(image, contours): \n",
    "    i = 0\n",
    "    for contour in contours: \n",
    "        #Create a blank mask for each contour\n",
    "        white_mask = np.zeros(cropped_image.shape[:2], dtype=np.uint8)\n",
    "        \n",
    "        # Draw contour onto the mask\n",
    "        cv2.drawContours(white_mask, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "        # Dilate the mask to include a border around the contour\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        dilated_white_mask = cv2.dilate(white_mask, kernel, iterations=1)\n",
    "\n",
    "        # Calculate the area covered by the dilated mask excluding the original mask\n",
    "        mask_diff = cv2.subtract(dilated_white_mask, white_mask)\n",
    "\n",
    "        # Apply the mask difference to the original image and calculate the mean color\n",
    "        mean_color = cv2.mean(image, mask=mask_diff)[:3]            \n",
    "        mean_color = tuple([int(c) for c in mean_color])\n",
    "    \n",
    "        # Replace the color in the modified image only where white_mask is 255\n",
    "        image[dilated_white_mask == 255] = mean_color\n",
    "        i += 1\n",
    "        pbar.update(1)\n",
    "    print(\"Number of detected and processed contours:\", len(contours))\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35a413d4-1885-41bf-9540-918f2e968db7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8685 contours were detected. Based on previous experience removing the reflection will take approximately 58.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Find all the contours (white zones) in the binary image\n",
    "contours, _ = cv2.findContours(cropped_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw the contours on the original image and run the reflection removal code\n",
    "image_with_contours = cropped_image.copy()\n",
    "cv2.drawContours(image_with_contours, contours, -1, (0, 255, 255), -1)\n",
    "print(len(contours), 'contours were detected. Based on previous experience removing the reflection will take approximately', round(len(contours)/1000*6.7, 0), 'minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88336a0c-ccc4-4cf2-ba6f-28ae5b529713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed Contours: 100%|\u001b[36m██████████████████████████████████████████████████████████\u001b[0m| 8685/8685 [50:56<00:00,  2.84it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected and processed contours: 8685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove the reflection by replacing white contours with the average color of the area around them\n",
    "# displays a progress bar\n",
    "# if you run this code multiple times, there might be an issue with the progress bar (for every perecentage a new line appears) \n",
    "# if this happens, run: pbar.close() before the rest of the code\n",
    "#pbar.close()\n",
    "pbar = tqdm(total = len(contours), desc = 'Processed Contours', colour = 'cyan')\n",
    "image_filled = replace_white_color(cropped_image.copy(), contours)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6df27185-8eec-4382-9e65-146d524f4d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image with the contours of white pixels highlighted in yellow\n",
    "concatenated_image = np.concatenate((image_with_contours, image_filled), axis=0) \n",
    "\n",
    "cv2.imshow(\"Detected Reflection (yellow) and Image without Reflection\", concatenated_image)\n",
    "cv2.imwrite(os.path.join(results_path, f\"{image_name}_withoutReflection.tif\"), image_filled)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cdd178-5a7d-4e20-a82d-17d96b0968e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Part 3: Identifying the Seagrass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028f14ae-0b51-4f51-ac6e-ca684c81fd32",
   "metadata": {},
   "source": [
    "*input: cropped image without reflection (image_without_reflection)  \n",
    "output: binary image where seagrass appears in white (dbo_binary)*  \n",
    "This section of the code highlights all the seagrass within a given tif file. First, the image is converted from RGB (red green blue) to HSV (hue saturation value) as these are closer to human perception of color and thus easier to work with. The threshold HSV values can be selected, based on which the code selects all areas that fall within the threshold. The code then opens a window in which an outline of all the selected seagrass areas is shown.  \n",
    "As the values between different picture, the code allows the user to select points on the outlined image, for which the HSV values are returned. This helps the user adapt the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07b6e01f-d095-4449-8026-405eb6266ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_without_reflection = cv2.imread(os.path.join(results_path, f\"{image_name}_withoutReflection.tif\"), image_filled)\n",
    "\n",
    "def segment_dark_blue_objects(image, lower_bound, upper_bound):\n",
    "    hsv_image = cv2.cvtColor(image_without_reflection, cv2.COLOR_BGR2HSV)\n",
    "    dark_blue_mask = cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
    "    dark_blue_objects = cv2.bitwise_and(image, image, mask=dark_blue_mask)\n",
    "    return dark_blue_objects\n",
    "    \n",
    "def draw_outlines(binary_image):\n",
    "    # find contours of binary image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # draw contours\n",
    "    image_with_contours = image_without_reflection.copy()\n",
    "    cv2.drawContours(image_with_contours, contours, -1, (0, 255, 255), 2)\n",
    "\n",
    "    # display outlines\n",
    "    cv2.imshow('Outlines', image_with_contours)\n",
    "    cv2.imwrite(os.path.join(results_path, f'{image_name}_outlines.tif'), image_with_contours)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b3607b6-dc0a-4388-8e07-9956566ddabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment dark blue objects\n",
    "blue_min = np.array([92, 0, 70])\n",
    "blue_max = np.array([110, 190, 200])\n",
    "dark_blue_objects = segment_dark_blue_objects(image_without_reflection, blue_min, blue_max)\n",
    "\n",
    "# create binary of the dark blue objects (dbo) for further processing\n",
    "dbo_grayscale = cv2.cvtColor(dark_blue_objects, cv2.COLOR_RGB2GRAY)\n",
    "_, dbo_binary = cv2.threshold(dbo_grayscale, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "draw_outlines(dbo_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3317c2c3-bd99-4c8e-93dc-094ac05bbde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 91 138 155]\n",
      "[ 90 126 152]\n",
      "[ 90 119 154]\n",
      "[ 90 141 137]\n",
      "[ 91 130 145]\n",
      "[ 94 127 130]\n",
      "[ 92  95 179]\n",
      "[ 91 114 148]\n"
     ]
    }
   ],
   "source": [
    "image_with_contours = cv2.imread(os.path.join(results_path, f'{image_name}_outlines.tif'))\n",
    "cv2.namedWindow(\"Seagrass Point Selection\")\n",
    "cv2.imshow(\"Seagrass Point Selection\", image_with_contours)\n",
    "seagrass_points = []\n",
    "def on_mouse_click(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Add the point to the list of red points\n",
    "        seagrass_points.append((y, x))\n",
    "                \n",
    "        # Display the clicked point in red\n",
    "        cv2.circle(image, (y, x), 2, (0, 255, 0), -1)\n",
    "\n",
    "cv2.setMouseCallback(\"Seagrass Point Selection\", on_mouse_click)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "seagrass_points\n",
    "HSV = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2HSV)\n",
    "for point in seagrass_points:\n",
    "    print(HSV[point])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34c97b7-5cd2-45e9-af16-b9cb610416c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Part 4: Refining Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9f66a028-c7e5-439c-8280-faeb45ac2c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the functions to remove noise and fill seagrass patches\n",
    "def remove_noise(image, kernel_size, iterations):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(kernel_size, kernel_size))\n",
    "    image_without_noise = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel, iterations = iterations)\n",
    "    return image_without_noise\n",
    "    \n",
    "\n",
    "def fill_holes(image, kernel_size, iterations):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(kernel_size, kernel_size))\n",
    "    image_with_filled_patches = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel, iterations=iterations)\n",
    "    return image_with_filled_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "53df5b0d-8399-40d2-a425-17e144554443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove noise and fill up the holes in the seagrass patches\n",
    "# the kernel size and amount of iterations can be changed\n",
    "\n",
    "image_without_noise = remove_noise(dbo_binary, 3, 5)\n",
    "image_with_filled_patches = fill_holes(image_without_noise, 3, 10)\n",
    "\n",
    "draw_outlines(image_with_filled_patches)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "51b8dc46-6639-4aa3-a473-5f3b983d1f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when happy with the result, save the refined (binary) image to the results folder\n",
    "\n",
    "cv2.imwrite(os.path.join(results_path, f\"{image_name}_SeagrassBinary.tif\"), image_with_filled_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecfa93b-f3f6-4273-b2af-e0c8e1192892",
   "metadata": {},
   "source": [
    "Congratulations, this part of the code is now done! To continue working with the seagrass areas, please refer to the protocol and move on to section 2, in which the binary tif is georeferenced and transformed into a vector shapefile that can be used in QGIS. (Unfortunately, it seems that importing GDAL, a library made for working with geographical data, in this environment causes conflicts with cv2, which is why I highly recommend creating a new environment and linking it to an ipykernel to avoid this conflict.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab03db7-98dd-47e2-9e89-85b2ebdb706d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 6: Quantifying the Seagrass Areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2fe8cc-4098-417d-93df-b23c2111f6b7",
   "metadata": {},
   "source": [
    "*Input: Binary picture of the detected seagrass, pixel size  \n",
    "Output: Calculated Seagrass Area*  \n",
    "This section of the code calculates the detected seagrass area based on the pixel size, which is given through Section 2: Georeferencing. At a flying height of 100 metres, every pixel is approxiamtely equivalent to 5 cm. Based on the amount of detected pixels, the area is then calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9041ac9d-3d70-429d-9bc8-ccbcf7751bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function that computes the total amount of white pixels and then calculates the area in cm2, m2, and ha based on that\n",
    "\n",
    "def calculate_white_area(image, pixel_size):\n",
    " \n",
    "    # Check if the image was loaded correctly\n",
    "    if image is None:\n",
    "        print(\"Error: Image not loaded correctly.\")\n",
    "        return\n",
    "\n",
    "    # Count the number of white pixels (value 255)\n",
    "    white_pixel_count = cv2.countNonZero(image[:,:,0])\n",
    "\n",
    "    # Calculate the pixel area based on the pixel size\n",
    "    area_per_pixel_in_cm2 = (pixel_size ** 2) * 10000\n",
    "    area_per_pixel_in_m2 = (pixel_size ** 2)\n",
    "\n",
    "    # Total area in square metres\n",
    "    area_m2 = white_pixel_count * area_per_pixel_in_m2\n",
    "\n",
    "    # Convert area to hectares\n",
    "    area_hectares = area_m2 / 10000\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Number of white pixels: {white_pixel_count}\")\n",
    "    print(f\"Area covered by one pixels: {round(area_per_pixel_in_cm2, 2)} square centimetres\")\n",
    "    print(f\"Covered area: {round(area_m2, 2)} square meters\")\n",
    "    print(f\"Covered area: {round(area_hectares, 4)} hectares\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e7c3f9e-afc8-4414-8598-428d4c13681e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of white pixels: 3544519\n",
      "Area covered by one pixels: 25.25 square centimetres\n",
      "Covered area: 8950.98 square meters\n",
      "Covered area: 0.8951 hectares\n"
     ]
    }
   ],
   "source": [
    "# Define inputs and run function\n",
    "seagrass_image = cv2.imread(os.path.join(results_path, f\"{image_name}_SeagrassBinary.tif\"))\n",
    "\n",
    "# Ground Sample Distance in centimeters / pixel\n",
    "pixel_size = 0.05025239034331673\n",
    "\n",
    "# Calculate and display the white area\n",
    "calculate_white_area(seagrass_image, pixel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09a7f93d-f81d-41e6-98fe-92d3b249033a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function countNonZero:\n",
      "\n",
      "countNonZero(...)\n",
      "    countNonZero(src) -> retval\n",
      "    .   @brief Counts non-zero array elements.\n",
      "    .\n",
      "    .   The function returns the number of non-zero elements in src :\n",
      "    .   \\f[\\sum _{I: \\; \\texttt{src} (I) \\ne0 } 1\\f]\n",
      "    .\n",
      "    .   The function do not work with multi-channel arrays. If you need to count non-zero array\n",
      "    .   elements across all the channels, use Mat::reshape first to reinterpret the array as\n",
      "    .   single-channel. Or you may extract the particular channel using either extractImageCOI, or\n",
      "    .   mixChannels, or split.\n",
      "    .\n",
      "    .   @note\n",
      "    .   - If only whether there are non-zero elements is important, @ref hasNonZero is helpful.\n",
      "    .   - If the location of non-zero array elements is important, @ref findNonZero is helpful.\n",
      "    .   @param src single-channel array.\n",
      "    .   @sa  mean, meanStdDev, norm, minMaxLoc, calcCovarMatrix\n",
      "    .   @sa  findNonZero, hasNonZero\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ec8600e-2e2d-496b-978d-e966d8281e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]], shape=(6217, 3), dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75dc57f6-836f-4e6a-a5aa-de764b99bbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3568, 6217, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(seagrass_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d33efa-f3c2-4df4-a361-45c35f6a2f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SeagrassImagery",
   "language": "python",
   "name": "seagrassimagery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
